#!/usr/bin/env python
import logging
import os.path
from urlparse import urlparse, parse_qs
from time import sleep

import argparse
import tempita

import ptpapi

def ellipsize(string, length):
    if len(string) > length:
        return string[:length-3] + '...'
    return string


def do_inbox(api, args):
    page = args.page
    user = api.current_user()
    if args.mark_all_read:
        print "Clearing out {0} messages".format(user.get_num_messages())
        while user.new_messages > 0:
            for msg in api.current_user().inbox(page=page):
                if msg['Unread'] is False:
                    continue
                user.inbox_conv(msg['ID'])
            page += 1
    elif args.conversation:
        conv = user.inbox_conv(args.conversation)
        print conv['Subject']
        for msg in conv['Message']:
            print "{0} - {1}\n".format(msg['User'], msg['Time'])
            print msg['Text']
            print '----------------------------'
    elif args.mark_read:
        for conv in args.mark_read:
            user.inbox_conv(conv)
    else:
        msgs = list(user.inbox())
        print "ID" + ' '*6 + "Subject" + ' '*25 + 'Sender' + ' '*9
        print '-'*55
        for msg in msgs:
            if args.unread and msg['Unread'] is False:
                continue
            if args.user is not None and msg['Sender'] != args.user:
                continue
            print "{0: <8}{1: <32}{2: <15}".format(
                msg['ID'],
                ellipsize(msg['Subject'], 30),
                ellipsize(msg['Sender'], 15))


def parse_terms(termlist):
    """Takes an array of terms, and sorts them out into 4 categories:
       * torrent URLs
       * movie URLs
       * targets (where to perform the search e.g. collages or bookmarks)
       * all other search parameters
    """
    torrents = []
    movies = []
    terms = {}
    target = 'torrents'

    for arg in termlist:
        url = urlparse(arg)
        url_args = parse_qs(url.query)
        if url.path == '/collages.php':
            target = 'collage'
            terms['id'] = url_args['id'][0]
        elif 'torrentid' in url_args:
            torrents.append(ptpapi.Torrent(url_args['torrentid'][0]))
        elif 'id' in url_args:
            if 'action' in url_args and url_args['action'][0] == 'download':
                torrents.append(ptpapi.Torrent(url_args['id'][0]))
            else:
                movies.append(ptpapi.Movie(url_args['id'][0]))
        else:
            term = arg.partition('=')
            if not term[2]:
                if term[0] == 'bookmarks':
                    target = 'bookmarks'
                else:
                    terms['searchstr'] = term[0]
            else:
                term_map = {
                    'taglist': ['genre', 'genres', 'tags'],
                    'searchstr': ['name', 'title']
                }
                for key, value in term_map.items():
                    if term[0] in value:
                        term = (key, term[1], term[2])
                terms[term[0]] = term[2]
    return (target, movies, torrents, terms)


def do_search(api, args):
    logger = logging.getLogger(__name__)
    (target, movies, torrents, terms) = parse_terms(args.search_terms)
    if args.movie_format == "":
        movie_template = None # Just to make linting happy
    elif args.movie_format is not None:
        movie_template = tempita.Template(args.movie_format)
    else:
        movie_template = tempita.Template("{{Title}} ({{Year}}) - {{','.join([d['Name'] for d in Directors])}} - "
                                          "[{{'/'.join(Tags)}}] - [PTP {{GroupId}}, IMDB tt{{ImdbId}}]")
    if args.torrent_format == "":
        torrent_template = None
    elif args.torrent_format is not None:
        torrent_template = tempita.Template(args.torrent_format)
    else:
        torrent_template = tempita.Template(u"{{if GoldenPopcorn}}\u2606{{else}}-{{endif}} {{Codec}}/{{Container}}/{{Source}}/{{Resolution}}"
                                            " - {{ReleaseName}} - {{Snatched}}/{{Seeders}}/{{Leechers}}")

    # If we haven't found any URL-looking things
    if not movies and not torrents:
        logger.debug('Attempting to search target "%s" with terms %s', target, terms)
        if target == 'torrents':
            movies = api.search(terms)
        elif target == 'bookmarks':
            movies = api.current_user().bookmarks(search_terms=terms)
        elif target == 'collage':
            movies = api.collage(terms['id'], terms)
        movies = movies[:args.limit]

    if args.download:
        for movie in movies[:args.limit]:
            if movie_template:
                print movie_template.substitute(movie)
            match = movie.best_match(args.filter)
            if match:
                if torrent_template:
                    print torrent_template.substitute(match)
                if not args.dry_run:
                    match.download_to_file(args.output_directory)
                else:
                    logger.info("Dry-run, not downloading %s", match)
            else:
                logger.info("No match found for for movie %s (%s)", movie['Title'], movie['Year'])
        for torrent in torrents:
            if args.download and not args.dry_run:
                if torrent_template:
                    print torrent_template.substitute(torrent)
                torrent.download_to_file(args.output_directory)
            elif args.dry_run:
                logger.info("Dry-run, not downloading %s", torrent)
    else:
        for movie in movies[:args.limit]:
            if movie_template:
                print movie_template.substitute(movie)
            for torrent in movie['Torrents']:
                if torrent_template:
                    print torrent_template.substitute(torrent)
        for torrent in torrents:
            if torrent_template:
                print torrent_template.substitute(torrent)


def do_raw(_, args):
    """Given a URL, download the raw HTML to the current directory"""
    for url_str in args.url:
        url = urlparse(url_str)
        data = ptpapi.session.session.base_get('?'.join([url.path, url.query])).content
        with open(os.path.basename(url.path), 'w') as fileh:
            fileh.write(data)


def do_log(api, args):
    interval = 30.0
    lastmsg = None
    while True:
        printmsg = False
        msgs = api.log()
        # We actually want it 'reversed' by default, with the newest at the bottom
        if not args.reverse:
            msgs.reverse()
        for time, msg in msgs:
            if lastmsg is None or printmsg:
                print time, '-', msg
                lastmsg = msg
            if lastmsg == msg:
                printmsg = True
        if args.follow:
            sleep(interval)
        else:
            break

def do_fields(api, args):
    print "Movie:"
    m = ptpapi.Movie(ID=1)
    for values in m.key_finder.values():
        for val in values:
            print "- {0}".format(val)
    print "Torrent:"
    t = ptpapi.Torrent(ID=1)
    for values in t.key_finder.values():
        for val in values:
            print "- {0}".format(val)

def add_verbosity_args(parser):
    """Helper function to improve DRY"""
    parser.add_argument('--debug', help='Print lots of debugging statements',
                        action="store_const", dest="loglevel", const=logging.DEBUG, default=logging.WARNING)
    parser.add_argument('-v', '--verbose', help='Be verbose', action="store_const", dest="loglevel", const=logging.INFO)
    parser.add_argument('-q', '--quiet', help='Hide most messages', action="store_const", dest="loglevel", const=logging.CRITICAL)


def main():
    logger = logging.getLogger(__name__)
    parser = argparse.ArgumentParser(description='Extensible command line utility for PTP')
    add_verbosity_args(parser)
    subparsers = parser.add_subparsers()

    search_parent = argparse.ArgumentParser()
    add_verbosity_args(search_parent)
    search_parent.add_argument('search_terms', help="""A list of terms in [field]=[text] format.
                               If the '=' is omitted, the field is assumed to be 'name'.""", nargs='+', metavar='term')
    search_parent.add_argument('-n', '--dry-run', help="Don't actually download any torrents", action='store_true')
    search_parent.add_argument('-l', '--limit', help="Limit search results to N movies", default=100, type=int)
    search_parent.add_argument('-f', '--filter', help="Define a filter to download movies with",
                               default=ptpapi.config.config.get('Main', 'filter'))
    search_parent.add_argument('-m', '--movie-format', help="Set the output for movies", default=None)
    search_parent.add_argument('-t', '--torrent-format', help="Set the output for torrents", default=None)
    search_parent.add_argument('-o', '--output-directory', help="Location for any downloaded files", default=None)

    search_parser = subparsers.add_parser('search', help='Search for or download movies', add_help=False, parents=[search_parent])
    search_parser.add_argument('-d', '--download', help="Download any movies found", action="store_true")
    search_parser.set_defaults(func=do_search)

    download_parser = subparsers.add_parser('download', help='An alias for `search -d`', add_help=False, parents=[search_parent])
    download_parser.add_argument('-d', '--download', help="Download any movies found", action="store_true", default=True)
    download_parser.set_defaults(func=do_search)

    inbox_parser = subparsers.add_parser('inbox', help='Reads messages in your inbox')
    add_verbosity_args(inbox_parser)
    inbox_parser.add_argument('-u', '--unread', help="Only show unread messages", action="store_true")
    inbox_parser.add_argument('-m', '--mark-read', help="Mark messages as read", type=lambda s: [int(n) for n in s.split(',')])
    inbox_parser.add_argument('--mark-all-read', help="Scan and mark all messages as read. "
                              "WARNING: If new messages arrive while this is running, the script can get caught in a loop until it reaches the end of the inbox's pages", action="store_true")
    inbox_parser.add_argument('--user', help="Filter messages by the sender")
    inbox_parser.add_argument('-c', '--conversation', help="Get the messages of a specific conversation", type=int)
    inbox_parser.add_argument('-p', '--page', help="Start at a certain page", type=int, default=1)
    inbox_parser.set_defaults(func=do_inbox)

    raw_parser = subparsers.add_parser('raw', help='Fetch the raw HTML of pages')
    add_verbosity_args(raw_parser)
    raw_parser.add_argument('url', help="A list of urls to download", nargs='+')
    raw_parser.set_defaults(func=do_raw)

    field_parser = subparsers.add_parser('fields', help='List the fields available for each PTPAPI resource')
    add_verbosity_args(field_parser)
    field_parser.set_defaults(func=do_fields)

    log_parser = subparsers.add_parser('log', help='Show the log of recent events')
    add_verbosity_args(log_parser)
    log_parser.add_argument('-r', '--reverse', help='Sort in reverse', action='store_true')
    log_parser.add_argument('-f', '--follow', help='Print new entries as they appear', action="store_true")
    log_parser.set_defaults(func=do_log)

    args = parser.parse_args()

    logging.basicConfig(level=args.loglevel)

    api = ptpapi.login()

    args.func(api, args)
    logger.debug("Total session tokens consumed: %s", ptpapi.session.session.consumed_tokens)
    logger.debug("Exiting...")

if __name__ == '__main__':
    main()
